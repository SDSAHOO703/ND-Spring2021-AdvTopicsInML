{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "departmental-michael",
   "metadata": {
    "id": "departmental-michael"
   },
   "source": [
    "# Mini-Project #3 (ANN)\n",
    "\n",
    "Student Name: **Subhadyuti Sahoo**\n",
    "<br>\n",
    "Course: **Adv Topics in Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-paste",
   "metadata": {
    "id": "urban-paste"
   },
   "source": [
    "### Importing Necessary Libraries, Modules and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brazilian-thomson",
   "metadata": {
    "id": "brazilian-thomson"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import warnings\n",
    "from numpy.random import seed\n",
    "tf.random.set_seed(1234)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-satisfaction",
   "metadata": {},
   "source": [
    "<a id='Goal'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Goal.</b>\n",
    "\n",
    "In this mini-project, you will explore the possibility of using artificial neural networks to predict the stock market, in particular the price of a very interesting stock NASDAQ: NVDA (NVIDIA Corporation). Below is its historic price chart. You can see that its per share price has jumped from USD $22$ to USD $615$ in the past $12$ years, a return of $28$x. In other words, if you had invested USD $1,000$ in NVDA in $2015$, your account would now have a balance of about USD $28,000$. Of course, we cannot look back; we can only look forward. The question is then: since we have plenty of data (we can get the historic price of about every stock), can we build a machine learning model on it so that we can identify the next NVDA? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-syntax",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/NVDAStockPrices.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-native",
   "metadata": {},
   "source": [
    "<a id='Description'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Description.</b>\n",
    "\n",
    "The project will use the historic adjusted closing price data of NVDA as the training/test data and build an artificial neural network (ANN) to predict the price in the future. The file NVDA.csv provided by NASDAQ contains the opening price, intra-day high, intra-day low, closing price, adjusted closing price and trading volume of each trading day since January $22$, $1999$ (for a total of $5,566$ trading days). For this project we will only use the adjusted closing price. We will $60:20:20$ split the data for training, validation and test, reserving the most recent $20\\%$ data for test, as though we had traveled back in time to September $30, 2016$. You will have access to any data on or before that date to train/validate your model, and will use the data after that date to test your model.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-genesis",
   "metadata": {
    "id": "emotional-genesis"
   },
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "novel-mother",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "novel-mother",
    "outputId": "fdf5dca0-c6ab-4d80-fbd9-8003bdc1c250"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-01-22</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>1.552083</td>\n",
       "      <td>1.640625</td>\n",
       "      <td>1.508412</td>\n",
       "      <td>67867200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-25</td>\n",
       "      <td>1.770833</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.640625</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>1.666436</td>\n",
       "      <td>12762000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-26</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.869792</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.671875</td>\n",
       "      <td>1.537143</td>\n",
       "      <td>8580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-27</td>\n",
       "      <td>1.677083</td>\n",
       "      <td>1.718750</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.532354</td>\n",
       "      <td>6109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-28</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.677083</td>\n",
       "      <td>1.651042</td>\n",
       "      <td>1.661458</td>\n",
       "      <td>1.527566</td>\n",
       "      <td>5688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>542.130005</td>\n",
       "      <td>553.669983</td>\n",
       "      <td>553.669983</td>\n",
       "      <td>8802500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.820007</td>\n",
       "      <td>535.840027</td>\n",
       "      <td>536.250000</td>\n",
       "      <td>536.250000</td>\n",
       "      <td>6585500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>537.049988</td>\n",
       "      <td>538.059998</td>\n",
       "      <td>511.950012</td>\n",
       "      <td>512.190002</td>\n",
       "      <td>512.190002</td>\n",
       "      <td>9408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>512.030029</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>483.350006</td>\n",
       "      <td>494.809998</td>\n",
       "      <td>494.809998</td>\n",
       "      <td>14292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>502.000000</td>\n",
       "      <td>502.000000</td>\n",
       "      <td>467.170013</td>\n",
       "      <td>498.459991</td>\n",
       "      <td>498.459991</td>\n",
       "      <td>13547800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5566 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     1999-01-22    1.750000    1.953125    1.552083    1.640625    1.508412   \n",
       "1     1999-01-25    1.770833    1.833333    1.640625    1.812500    1.666436   \n",
       "2     1999-01-26    1.833333    1.869792    1.645833    1.671875    1.537143   \n",
       "3     1999-01-27    1.677083    1.718750    1.583333    1.666667    1.532354   \n",
       "4     1999-01-28    1.666667    1.677083    1.651042    1.661458    1.527566   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "5561  2021-03-01  555.000000  557.000000  542.130005  553.669983  553.669983   \n",
       "5562  2021-03-02  556.000000  556.820007  535.840027  536.250000  536.250000   \n",
       "5563  2021-03-03  537.049988  538.059998  511.950012  512.190002  512.190002   \n",
       "5564  2021-03-04  512.030029  519.000000  483.350006  494.809998  494.809998   \n",
       "5565  2021-03-05  502.000000  502.000000  467.170013  498.459991  498.459991   \n",
       "\n",
       "        Volume  \n",
       "0     67867200  \n",
       "1     12762000  \n",
       "2      8580000  \n",
       "3      6109200  \n",
       "4      5688000  \n",
       "...        ...  \n",
       "5561   8802500  \n",
       "5562   6585500  \n",
       "5563   9408000  \n",
       "5564  14292400  \n",
       "5565  13547800  \n",
       "\n",
       "[5566 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forming the pandas dataframe\n",
    "# entireDataSet = pd.read_csv('/content/drive/My Drive/AdvTopicsInML/NVDA.csv')   # for Google Colab\n",
    "entireDataSet = pd.read_csv('NVDA.csv')   # for Jupyter Notebook\n",
    "\n",
    "# Displaying the pandas dataFrame\n",
    "display(entireDataSet)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eXYzKp6TzleU",
   "metadata": {
    "id": "eXYzKp6TzleU"
   },
   "source": [
    "### Extracting The Working Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46MjPZszzjgQ",
   "metadata": {
    "id": "46MjPZszzjgQ"
   },
   "outputs": [],
   "source": [
    "dSet = pd.DataFrame(entireDataSet['Adj Close'], columns=['Adj Close'])   # Working with only the Adjusted Closing Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-cooperation",
   "metadata": {
    "id": "tutorial-cooperation"
   },
   "source": [
    "### Checking for Missing Values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proprietary-nerve",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "proprietary-nerve",
    "outputId": "b805026e-9d59-456c-b46e-5615410515c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking for Missing Values ---\n",
      "Q. Are there any missing values in the dataset?\n",
      "A. No\n",
      "-----------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if there are missing values in the workign dataset\n",
    "result = (dSet.isna().values.any()) or (dSet.isnull().values.any())\n",
    "if (result == True):\n",
    "    n_missing_values = dSet.isna().sum().sum() + dSet.isnull().sum().sum()\n",
    "\n",
    "# Displaying if there are any missing values in dataFrame\n",
    "print('--- Checking for Missing Values ---')\n",
    "print('Q. Are there any missing values in the dataset?')   \n",
    "if (result == True):\n",
    "    print('A. Yes')\n",
    "    print('Q. How many?')\n",
    "    print('A. ', n_missing_values)\n",
    "else:\n",
    "    print('A. No') \n",
    "print('-----------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tIdQ559W3qtu",
   "metadata": {
    "id": "tIdQ559W3qtu"
   },
   "source": [
    "### Splitting the Working Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vTohyOwUxqe_",
   "metadata": {
    "id": "vTohyOwUxqe_"
   },
   "outputs": [],
   "source": [
    "# Splitting the data after September 30, 2016\n",
    "dates = entireDataSet['Date'].to_numpy()\n",
    "trainval_indices = np.where(dates < '2016-10-01')\n",
    "trainval_index_start = trainval_indices[0][0]\n",
    "trainval_index_end = trainval_indices[0][-1]\n",
    "\n",
    "# Splitting the working dataset into train, val and test datasets\n",
    "n = (0.6 * len(dSet)) / trainval_index_end\n",
    "trainDataSet = dSet[:int(n*trainval_index_end)]\n",
    "valDataSet = dSet[int(n*trainval_index_end):trainval_index_end+1]\n",
    "testDataSet = dSet[trainval_index_end+1:]\n",
    "tempTestDates = entireDataSet['Date'][trainval_index_end+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-visiting",
   "metadata": {},
   "source": [
    "<a id='QuestionA'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Question.</b>\n",
    " \n",
    "To get you started, an interesting observation you can make is that NVDA price remained mostly flat between 2010 and 2015, and then it started to soar. In one sentence, explain why (remember this is a computer science class, not finance).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-saturday",
   "metadata": {},
   "source": [
    "<a id='AnswerA'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Answer.</b>\n",
    " \n",
    "The NVDA price started to soar since 2015 because universities, companies and machine learning enthusiasts across the globe came to realize that if CUDA cores in NVIDIA GPUs could be used for enhancing video quality during computer video games, such cores could also be used for training deep neural networks, especially for image- and video-related machine learning and deep learning problems, which lead to bulk-purchasing of NVIDIA GPUs.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BL7wB1_MH7IB",
   "metadata": {
    "id": "BL7wB1_MH7IB"
   },
   "source": [
    "<a id='QuestionB'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Question.</b>\n",
    " \n",
    "Now a quantitative research intern at a hedge fund designs a two-layer ANN with $\\texttt{200}$ hidden neurons to predict the next day’s NVDA adjusted closing price using the past thirty days. Do you see any issue to train such a network on the data provided? Please explain (you will need to do some math here). \n",
    " \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k6ytWDzfIq0F",
   "metadata": {
    "id": "k6ytWDzfIq0F"
   },
   "source": [
    "### Creating the ANN Model containing 1 Hidden Layer with 200 Hidden Neurons for 30 Prior Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1jIj05QLIDpY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "1jIj05QLIDpY",
    "outputId": "e01633dc-a2c0-4d53-8925-dc8ef042179b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               6200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 6,401\n",
      "Trainable params: 6,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model302001 = Sequential()\n",
    "model302001.add(Dense(units=200, activation='relu', input_dim=30))\n",
    "model302001.add(Dense(units=1))\n",
    "model302001.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-chamber",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/model302001.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-identifier",
   "metadata": {},
   "source": [
    "<a id='AnswerB'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Answer.</b>\n",
    " \n",
    "$$\n",
    "\\texttt{Number of Model Parameters}\n",
    "= \\Big( (30 + 1) \\times 200 \\Big) + \\Big( (200 + 1) \\times 1 \\Big) \n",
    "= 6401\n",
    "$$\n",
    "    \n",
    "The number of model parameters is more than $\\texttt{210}$ times the number of training data (input neurons). This might cause overfitting during the training process which would then lead to erroneous predictions for validation and test datasets. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yY1zz168JNrY",
   "metadata": {
    "id": "yY1zz168JNrY"
   },
   "source": [
    "<a id='StudentTask'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Student Task.</b>\n",
    " \n",
    "So now we decide to build our own models to predict the next day’s NVDA adjusted closing price based on the past seven days. To extract the train/validation/test data, you may use a sliding window approach (i.e., the first sample would be the adjusted closing prices on the seven trading days between $1/22/99$ and $2/1/99$ and its label/target is USD $1.369541$, the adjusted closing price on $2/2/99$; the second sample would be the adjusted closing prices from $1/23/99$ to $2/2/99$ and the label/target would be that on $2/3/99$, etc). We will build $4$ two-layer ANNs, with $20$, $40$, $60$ and $80$ hidden neurons respectively. Use ReLU activation for all the neurons and mean squared error/sum of squared error as the objective function. \n",
    " \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m-0iAJwuxvZi",
   "metadata": {
    "id": "m-0iAJwuxvZi"
   },
   "source": [
    "### User-Defined Function to Form Training, Validation and Test Datasets Depending Upon Prior Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "MkgvI63Yy291",
   "metadata": {
    "id": "MkgvI63Yy291"
   },
   "outputs": [],
   "source": [
    "def get_refurbished_datasets(dataset, prior_days):\n",
    "  \"\"\"\n",
    "  Returns the reconfigured datasets for both 7 and 10 prior days\n",
    "  \n",
    "  Args: \n",
    "    dataset (vector, shape = [n, 1]): the column of interest from the entire, bigger dataset\n",
    "    prior_days (int): the number of prior days for which the column of interest needs to be reconfigured\n",
    "  \"\"\"\n",
    "\n",
    "  # Forming a dataset list to store values from the column of interest\n",
    "  dSetList = []\n",
    "\n",
    "  # Converting the received dataset into a numpy array for ease of operation\n",
    "  dataset = dataset.to_numpy()\n",
    "\n",
    "  # Forming the reconfigured datasets for 7 prior days\n",
    "  if prior_days == 7:\n",
    "    for i in range(len(dataset) - 7):\n",
    "      dSetList.append([dataset[i], dataset[i+1], dataset[i+2], dataset[i+3],\n",
    "                       dataset[i+4], dataset[i+5], dataset[i+6], dataset[i+7]])\n",
    "    head = ['Day1','Day2','Day3','Day4','Day5','Day6','Day7','Day8']\n",
    "    finalDataSet = pd.DataFrame(dSetList, columns = head)\n",
    "    X_ = finalDataSet[['Day1','Day2','Day3','Day4','Day5','Day6','Day7']].to_numpy()\n",
    "    y_ = finalDataSet['Day8'].to_numpy().reshape(-1,1)\n",
    "    \n",
    "  # Forming the reconfigured datasets for 10 prior days\n",
    "  else:\n",
    "    for i in range(len(dataset) - 10):\n",
    "      dSetList.append([dataset[i], dataset[i+1], dataset[i+2], dataset[i+3],\n",
    "                       dataset[i+4], dataset[i+5], dataset[i+6], dataset[i+7], \n",
    "                       dataset[i+8], dataset[i+9], dataset[i+10]])\n",
    "    head = ['Day1','Day2','Day3','Day4','Day5','Day6','Day7','Day8','Day9','Day10','Day11']\n",
    "    finalDataSet = pd.DataFrame(dSetList, columns = head)\n",
    "    X_ = finalDataSet[['Day1','Day2','Day3','Day4','Day5','Day6','Day7','Day8','Day9','Day10']].to_numpy()\n",
    "    y_ = finalDataSet['Day11'].to_numpy().reshape(-1,1)\n",
    "  \n",
    "  # Returning the reconfigured datasets\n",
    "  return X_, y_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7LY1h1f24kIm",
   "metadata": {
    "id": "7LY1h1f24kIm"
   },
   "source": [
    "### Forming the Working Datasets for Training, Validation and Test for 7 Prior Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rGwe2eV96FBd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGwe2eV96FBd",
    "outputId": "b0886dda-99ec-491d-a113-171ee43bbbe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Shapes of Each Dataset (7 Prior Days) ---\n",
      "Training Features Dataset Shape: (3332, 7)\n",
      "Training Labels Dataset Shape: (3332, 1)\n",
      "Validation Features Dataset Shape: (1107, 7)\n",
      "Validation Labels Dataset Shape: (1107, 1)\n",
      "Test Features Dataset Shape: (1106, 7)\n",
      "Test Labels Dataset Shape: (1106, 1)\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Forming the final training dataset\n",
    "X_train, y_train = get_refurbished_datasets(dataset=trainDataSet, prior_days=7)\n",
    "X_train = np.asarray(X_train).astype(np.float32)  # Converting to Tensor Form\n",
    "y_train = np.asarray(y_train).astype(np.float32)  # Converting to Tensor Form\n",
    "\n",
    "# Forming the final validation dataset\n",
    "X_val, y_val = get_refurbished_datasets(dataset=valDataSet, prior_days=7)\n",
    "X_val = np.asarray(X_val).astype(np.float32)  # Converting to Tensor Form\n",
    "y_val = np.asarray(y_val).astype(np.float32)  # Converting to Tensor Form\n",
    "\n",
    "# Forming the final validation dataset\n",
    "X_test, y_test = get_refurbished_datasets(dataset=testDataSet, prior_days=7)\n",
    "X_test = np.asarray(X_test).astype(np.float32)  # Converting to Tensor Form\n",
    "\n",
    "# Printing out the shapes of each dataset\n",
    "print('--- Shapes of Each Dataset (7 Prior Days) ---')\n",
    "print(f'Training Features Dataset Shape: {X_train.shape}')\n",
    "print(f'Training Labels Dataset Shape: {y_train.shape}')\n",
    "print(f'Validation Features Dataset Shape: {X_val.shape}')\n",
    "print(f'Validation Labels Dataset Shape: {y_val.shape}')\n",
    "print(f'Test Features Dataset Shape: {X_test.shape}')\n",
    "print(f'Test Labels Dataset Shape: {y_test.shape}')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fU-RqNRo53k0",
   "metadata": {
    "id": "fU-RqNRo53k0"
   },
   "source": [
    "### Creating A User-Defined Function to Build Customized ANN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "yNoY0tDB2TFQ",
   "metadata": {
    "id": "yNoY0tDB2TFQ"
   },
   "outputs": [],
   "source": [
    "def build_model(init_empty_model, trainFeatures, n_hiddenLayers, n_neurons):\n",
    "  \"\"\"\n",
    "  Returns the customized model \n",
    "  \n",
    "  Args:\n",
    "    init_empty_model (keras sequential model): the skeletion of the final model returned \n",
    "    trainFeatures (array, shape = [m, n]): the training dataset features\n",
    "    n_hiddenLayers (int): the number of hidden layers to be added to the skeleton model\n",
    "    n_neurons (int): the number of neurons each of the hidden layers are going to contain\n",
    "  \"\"\"\n",
    "\n",
    "  # Calcuate the input dimensions to be used for building the model\n",
    "  inputDim = trainFeatures.shape[1]\n",
    "\n",
    "  # Putting the skeleton model into the variable which is going to get filled up soon\n",
    "  filled_model = init_empty_model\n",
    "\n",
    "  # Building the final model which is gonna be returned \n",
    "  # this is when n_hiddenLayers == 1\n",
    "  filled_model.add(Dense(units = n_neurons,\n",
    "                             \n",
    "                         # Activation function for hidden layer\n",
    "                         activation = 'relu',\n",
    "\n",
    "                         input_dim = inputDim\n",
    "                        )\n",
    "                  )\n",
    "  \n",
    "  # this is when n_hiddenLayers == 2\n",
    "  if n_hiddenLayers==2:\n",
    "    filled_model.add(Dense(units = n_neurons, activation = 'relu'))\n",
    "    \n",
    "  # this is when n_hiddenLayers == 3\n",
    "  if n_hiddenLayers==3:\n",
    "    filled_model.add(Dense(units = n_neurons, activation = 'relu'))\n",
    "    filled_model.add(Dense(units = n_neurons, activation = 'relu'))\n",
    "  \n",
    "  # Adding the final output layer to the final model\n",
    "  filled_model.add(Dense(units=1))\n",
    "\n",
    "  # Returning the final model\n",
    "  return filled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QD_EFbFFQ_3G",
   "metadata": {
    "id": "QD_EFbFFQ_3G"
   },
   "source": [
    "### The ANN Models containing 1 Hidden Layer with Different No. of Hidden Neurons for 7 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-geneva",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/model_7_XX_1.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-cloud",
   "metadata": {},
   "source": [
    "<a id='StudentTask'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Student Task.</b>\n",
    " \n",
    "Plot the training and validation accuracy vs. training iteration (epochs) for each model (four figures in total).  \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EgZm_ZVHRUY3",
   "metadata": {
    "id": "EgZm_ZVHRUY3"
   },
   "source": [
    "### Creating A User-Defined Function In Order To Compile and Train Different ANN Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vU6ggNh19VO8",
   "metadata": {
    "id": "vU6ggNh19VO8"
   },
   "outputs": [],
   "source": [
    "def compile_and_fit(model, trainFeatures, trainLabels, valFeatures,\n",
    "                    valLabels, batchSize, n_epochs):\n",
    "  \"\"\"\n",
    "  Returns a compiled model\n",
    "  \n",
    "  Args:\n",
    "    model (keras sequential model): the filled model\n",
    "    trainFeatures (array, shape = [m,n]): the training dataset features\n",
    "    trainLabels (vector, shape = [m,1]): the training dataset labels\n",
    "    valFeatures (array, shape = [p, n]): the validation dataset features\n",
    "    valLabels (vector, shape = [p,1]): the validation dataset labels\n",
    "    batchSize (int): the max no. of batches to be used for compiling the model\n",
    "    n_epochs (int): the max no. iterations for simulating the model\n",
    "  \"\"\"\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(# Objective (Loss) Function\n",
    "                loss = 'mean_squared_error',  # meanSquaredError\n",
    "\n",
    "                # Optimizer\n",
    "                optimizer = 'adam'\n",
    "               )\n",
    "  \n",
    "  # Training the model\n",
    "  history = model.fit(x = trainFeatures,\n",
    "                      y = trainLabels,\n",
    "                      batch_size = batchSize, \n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = (valFeatures, valLabels))\n",
    "  \n",
    "  # Returning the compiled model\n",
    "  return history "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60izzbksBOlC",
   "metadata": {
    "id": "60izzbksBOlC"
   },
   "source": [
    "### Creating A User-Defined Function to Plot Mean Squared Error Values v/s No. of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "PR0nEONq-Z6m",
   "metadata": {
    "id": "PR0nEONq-Z6m"
   },
   "outputs": [],
   "source": [
    "def plot_mse(history, n_epochs, n_hiddenLayers, n_neurons, prior_days):\n",
    "  \"\"\"\n",
    "  Returns a plot with MSEs on y-axis and No. of Epochs on x-axis\n",
    "  \n",
    "  Args:\n",
    "    history (dict): the dictionary containing everything about the compiled cmodel\n",
    "    n_epcohs (int): the max no. of iterations used for simulating the model\n",
    "    n_hiddenLayers (int): the no. of hidden layers in the ANN model\n",
    "    n_neurons (int): the no. of neurons in each of the hidden layers\n",
    "    prior_days (int): the no. of days for which data was collected for daily prediction thereafter\n",
    "  \"\"\"\n",
    "\n",
    "  # Setting the string for title\n",
    "  eachStr = []\n",
    "  if n_hiddenLayers > 1:\n",
    "    eachStr.append('Each')\n",
    "    titleString = \"MSE vs No. of Epochs for the ANN Model \\n containing \"+str(n_hiddenLayers)+\" Hidden Layers with \"+str(n_neurons)+\" Neurons \"+eachStr[0]+\" (\"+str(prior_days)+\" Prior Days)\"\n",
    "  else:\n",
    "    titleString = \"MSE vs No. of Epochs for the ANN Model \\n containing \"+str(n_hiddenLayers)+\" Hidden Layer with \"+str(n_neurons)+\" Neurons (\"+str(prior_days)+\" Prior Days)\"\n",
    "\n",
    "  # Estimating the MSE values for training and validation\n",
    "  trainMSE = np.asarray(history.history['loss']).reshape(-1,1) \n",
    "  valMSE = np.asarray(history.history['val_loss']).reshape(-1,1)\n",
    "\n",
    "  # Plotting Accuracy Scores v/s No. of Epochs \n",
    "  horzLine = np.linspace(1, n_epochs)\n",
    "  horzLineData = np.array([0.00 for i in range(len(horzLine))])\n",
    "  fig, ax = plt.subplots(figsize=(7,6)) \n",
    "  ax.plot(horzLine, horzLineData, 'k--', LineWidth=2)\n",
    "  ax.plot(range(1, n_epochs+1), trainMSE, color='violet', label='Train')   \n",
    "  ax.plot(range(1, n_epochs+1), valMSE, color='darkslategray', label='Validation')   \n",
    "  ax.set_title(titleString, fontsize=16)  \n",
    "  ax.set_ylabel('Mean Squared Errors', fontsize=15)   \n",
    "  ax.set_xlabel('No. of Epochs', fontsize=15)  \n",
    "  ax.set_xlim(left=1, right=n_epochs)\n",
    "  ax.tick_params(axis='x', labelsize=14)\n",
    "  ax.tick_params(axis='y', labelsize=14)\n",
    "  ax.grid(axis='y', linestyle='-', alpha=0.5)\n",
    "  plt.legend(prop={'size': 14}, ncol=1, labelspacing=0.05, loc='upper right')   \n",
    "  plt.tight_layout()\n",
    "  plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uUCeZwL-R7y9",
   "metadata": {
    "id": "uUCeZwL-R7y9"
   },
   "source": [
    "### Plotting Mean Squared Errors v/s No. of Epochs for the ANN Models containing 1 Hidden Layer with Different No. of Hidden Neurons for 7 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-response",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/plotMSE_7_XX_1.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-browser",
   "metadata": {},
   "source": [
    "<a id='StudentTask'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Student Task.</b>\n",
    " \n",
    "Also, for each trained model, plot your predicted adjusted closing prices from $10/1/16$ to now and the actual prices with respect to time.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deiewyblGNQ0",
   "metadata": {
    "id": "deiewyblGNQ0"
   },
   "source": [
    "### Creating A User-Defined Function for Plotting Real and Predicted Adjusted Closing Prices between 10/12/2016 and 03/05/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "LNGZYSc2hbt6",
   "metadata": {
    "id": "LNGZYSc2hbt6"
   },
   "outputs": [],
   "source": [
    "def plot_prices(dates, testLabels, predTestLabels, \n",
    "                n_hiddenLayers, n_neurons, prior_days):\n",
    "  \"\"\"\n",
    "  Returns a plot with Adj Closing Prices on y-axis and Dates on x-axis\n",
    "  \n",
    "  Args:\n",
    "    dates (list): list of dates\n",
    "    testLabels (vector, shape = [p,1]): the test dataset labels\n",
    "    predTestLabels (vector, shape = [p,1]): the predicted test dataset labels\n",
    "    n_hiddenLayers (int): the no. of hidden layers in the ANN model\n",
    "    n_neurons (int): the no. of neurons in each of the hidden layers\n",
    "    prior_days (int): the no. of days for which data was collected for daily prediction thereafter\n",
    "  \"\"\"\n",
    "  \n",
    "  # Forming a pandas dataframe\n",
    "  testDates = dates.iloc[prior_days:]\n",
    "  dFrame = pd.DataFrame({'Date': testDates, \n",
    "                         'Real Prices': np.asarray(testLabels).astype(np.float64).flatten(), \n",
    "                         'Predicted Prices': predTestLabels.flatten()})\n",
    "\n",
    "  # Setting the string for title\n",
    "  eachStr = []\n",
    "  if n_hiddenLayers > 1:\n",
    "    eachStr.append('Each')\n",
    "    titleString = \"Adj Closing Prices vs Dates for the ANN Model \\n containing \"+str(n_hiddenLayers)+\" Hidden Layers with \"+str(n_neurons)+\" Neurons \"+eachStr[0]+\" (\"+str(prior_days)+\" Prior Days)\"\n",
    "  else:\n",
    "    titleString = \"Adj Closing Prices vs Dates for the ANN Model \\n containing \"+str(n_hiddenLayers)+\" Hidden Layer with \"+str(n_neurons)+\" Neurons (\"+str(prior_days)+\" Prior Days)\"\n",
    "\n",
    "  # Plotting the Predicted and Real Prices\n",
    "  fig, ax = plt.subplots(figsize=(7,6)) \n",
    "  dFrame.plot(ax = ax, \n",
    "              x = \"Date\", \n",
    "              y = [\"Real Prices\", \"Predicted Prices\"],\n",
    "              rot = 30)\n",
    "  ax.tick_params(axis='x', labelsize=14)\n",
    "  ax.tick_params(axis='y', labelsize=14)\n",
    "  ax.set_title(titleString, fontsize=16) \n",
    "  ax.set_xlabel('Dates', fontsize=15)\n",
    "  ax.set_ylabel('Adj Closing Prices \\n (USD)', fontsize=15)\n",
    "  ax.grid(axis='y', linestyle='-', alpha=0.5)\n",
    "  ax.legend(prop={'size': 14}, ncol=1, labelspacing=0.05, loc='upper left')\n",
    "  plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wYCxFcW-s2rr",
   "metadata": {
    "id": "wYCxFcW-s2rr"
   },
   "source": [
    "### Plotting The Predicted and Real Prices from 10/1/2016 to now for the ANN Models containing 1 Hidden Layer with Different No. of Hidden Neurons for 7 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-update",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/plotPrices_7_XX_1.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-rugby",
   "metadata": {},
   "source": [
    "<a id='StudentTask'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Student Task.</b>\n",
    " \n",
    "Compute the average accuracy (MSE) of the adjusted closing prices on the test data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6H2U2OFIOYdx",
   "metadata": {
    "id": "6H2U2OFIOYdx"
   },
   "source": [
    "### Plotting the MSE Values for Different ANN Models Trained So Far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-february",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/barPlotMSEFirstFour.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-recommendation",
   "metadata": {},
   "source": [
    "<a id='QuestionC004'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Question.</b>\n",
    " \n",
    "Comparing the four models, what can you observe and why? Would any of them provide satisfactory accuracy?  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-oxford",
   "metadata": {},
   "source": [
    "<a id='AnswerC004'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Answer.</b>\n",
    " \n",
    "$\\textbf{Observation}$: Although there are almost no perceptible differences in the real and adjusted closing prices for the different ANN models for $\\texttt{7}$ prior days, the differences are highly manifest in the training, validation and test accuracy scores (MSEs). If only the MSEs of the test dataset are concerned, then the two-layer ANN model with $\\texttt{20}$ hidden neurons in the hidden layer can provide satisfactory accuracy. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2iVOHzwYSq2G",
   "metadata": {
    "id": "2iVOHzwYSq2G"
   },
   "source": [
    "<a id='StudentTask'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Student Task.</b>\n",
    " \n",
    "Now re-do all the things from the previous part for two deeper ANN models: one with two hidden layers ($30$ neurons each), and one with three hidden layers ($20$ neurons each), and see if they can do a better job. Compare your results with the ANN model in previous part that has $60$ hidden neurons in one hidden layer. All these three models have the same number of neurons. \n",
    " \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-makeup",
   "metadata": {},
   "source": [
    "### The ANN Models with Different No. of Hidden Layers and Different No. of Hidden Neurons for 7 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-skill",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/model_7_30_20_1.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-pulse",
   "metadata": {},
   "source": [
    "### Comparing the Training and Validation MSEs of the Above Two ANN Models with those of the ANN Model with 1 Hidden Layer and 60 Hidden Neurons for 7 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-sugar",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/plotMSE_7_60_30_20.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-grave",
   "metadata": {},
   "source": [
    "### Comparing the Real and Predicted Adjusted Closing Prices from 10/1/2016 to now of the Above Two ANN Models with those of the ANN Model with 1 Hidden Layer and 60 Hidden Neurons for 7 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-mounting",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/plotPrices_7_60_30_20.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vvd31kQnRgMs",
   "metadata": {
    "id": "Vvd31kQnRgMs"
   },
   "source": [
    "### Plotting the MSE Values for Different ANN Models Trained So Far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-challenge",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/barPlotMSEFirstSix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-covering",
   "metadata": {},
   "source": [
    "<a id='QuestionD001'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Question.</b>\n",
    " \n",
    "What can you observe and why? Would any of them provide satisfactory accuracy?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-football",
   "metadata": {},
   "source": [
    "<a id='AnswerD001'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Answer.</b>\n",
    " \n",
    "$\\textbf{Observation}$: Just like the previous one, if only the MSEs of the test dataset are visually compared, then the ANN model with $\\texttt{30}$-$\\texttt{30}$ hidden neurons can provide satisfactory accuracy amongst the ANN models with $\\texttt{60}$, $\\texttt{30}$-$\\texttt{30}$ and $\\texttt{20}$-$\\texttt{20}$-$\\texttt{20}$ hidden neurons in the hidden layer(s). Otherwise, there is no perceptible differences in the real and predicted adjusted closing prices for these $\\texttt{3}$ ANN models.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bCsgDc1VeAaH",
   "metadata": {
    "id": "bCsgDc1VeAaH"
   },
   "source": [
    "<a id='StudentTask'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Student Task. </b>\n",
    " \n",
    "Now re-do the previous two parts but the model now uses the data from past $10$ days.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fCVrcbBdTOo",
   "metadata": {
    "id": "6fCVrcbBdTOo"
   },
   "source": [
    "### Forming the Working Datasets for Training, Validation and Test for 10 Prior Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "AxKHxARmdWDm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxKHxARmdWDm",
    "outputId": "fbfef110-0c81-40d6-ce9c-f11488970491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Shapes of Each Dataset ---\n",
      "Training Features Dataset Shape: (3329, 10)\n",
      "Training Labels Dataset Shape: (3329, 1)\n",
      "Validation Features Dataset Shape: (1104, 10)\n",
      "Validation Labels Dataset Shape: (1104, 1)\n",
      "Test Features Dataset Shape: (1103, 10)\n",
      "Test Labels Dataset Shape: (1103, 1)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Forming the final training dataset\n",
    "X_train, y_train = get_refurbished_datasets(dataset=trainDataSet, prior_days=10)\n",
    "X_train = np.asarray(X_train).astype(np.float32)  # Converting to Tensor Form\n",
    "y_train = np.asarray(y_train).astype(np.float32)  # Converting to Tensor Form\n",
    "\n",
    "# Forming the final validation dataset\n",
    "X_val, y_val = get_refurbished_datasets(dataset=valDataSet, prior_days=10)\n",
    "X_val = np.asarray(X_val).astype(np.float32)  # Converting to Tensor Form\n",
    "y_val = np.asarray(y_val).astype(np.float32)  # Converting to Tensor Form\n",
    "\n",
    "# Forming the final validation dataset\n",
    "X_test, y_test = get_refurbished_datasets(dataset=testDataSet, prior_days=10)\n",
    "X_test = np.asarray(X_test).astype(np.float32)  # Converting to Tensor Form\n",
    "\n",
    "# Printing out the shapes of each dataset\n",
    "print('--- Shapes of Each Dataset ---')\n",
    "print(f'Training Features Dataset Shape: {X_train.shape}')\n",
    "print(f'Training Labels Dataset Shape: {y_train.shape}')\n",
    "print(f'Validation Features Dataset Shape: {X_val.shape}')\n",
    "print(f'Validation Labels Dataset Shape: {y_val.shape}')\n",
    "print(f'Test Features Dataset Shape: {X_test.shape}')\n",
    "print(f'Test Labels Dataset Shape: {y_test.shape}')\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7SLAzZw4exrk",
   "metadata": {
    "id": "7SLAzZw4exrk"
   },
   "source": [
    "### The ANN Models containing Different No. of Hidden Layers with Different No. of Hidden Neurons for 10 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-truck",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/model_10_All.png\" width=850>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-color",
   "metadata": {},
   "source": [
    "### Plotting Training and Validation MSEs of the ANN Models containing Different No. of Hidden Layers with Different No. of Hidden Neurons for 10 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-artwork",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/plotMSE_10.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-silicon",
   "metadata": {},
   "source": [
    "### Plotting Real and Predicted Prices from 10/1/2016 to now for the ANN Models containing Different No. of Hidden Layers with Different No. of Neurons for 10 Prior Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-necessity",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/plotPrices_10.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-batman",
   "metadata": {},
   "source": [
    "### Plotting the MSE Values for Different ANN Models Trained So Far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-senate",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/barPlotMSEAllTwelve.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-guitar",
   "metadata": {},
   "source": [
    "<a id='QuestionE'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Question. </b>\n",
    " \n",
    "Do we get any benefits by using more data for the prediction? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-beach",
   "metadata": {},
   "source": [
    "<a id='AnswerE'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Answer. </b>\n",
    " \n",
    "$\\textbf{Benefits}$: Once again, if the real and predicted closing prices are visually compared, then no benefits could be observed. However, if MSEs of the test dataset are compared, then it can be safely inferred that the ANN model with $\\texttt{80}$ hidden neurons for $\\texttt{10}$ prior days is the <u>best one</u>  in my case because the MSE of the adjusted closing prices of the test dataset for this model is the <u>lowest</u> amongst all the models. \n",
    "\n",
    "\n",
    "\n",
    "$\\textbf{Final Conclusion}$: In my case, the ANN model with $\\texttt{80}$ hidden neurons in the hidden layer for $\\texttt{10}$ prior days is the <u>best model</u>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-exemption",
   "metadata": {},
   "source": [
    "<a id='StudentTask'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Student Task.</b>\n",
    " \n",
    "Use the best model you have to predict the adjusted closing price of NVDA on Wednesday ($3/24/2021$). \n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SS865AE7FtG8",
   "metadata": {
    "id": "SS865AE7FtG8"
   },
   "source": [
    "### Prediction of Adjusted Closing Price for 3/24/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-cloud",
   "metadata": {},
   "source": [
    "<img src=\"./plotsAndFigures/pricesLastTenDays.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-internship",
   "metadata": {},
   "source": [
    "<a id='AnswerF'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Answer.</b>\n",
    " \n",
    "Using my best model, I predict the adjusted closing price of NVDA on Wednesday ($3/24/2021$) to be $\\textbf{USD 532.89}$ (correct upto 2 places after decimal point). \n",
    "    \n",
    "$\\textbf{P.S.}$: The real (actual) adjusted closing price of NVDA on Wednesday ($3/24/2021$) was eventually $\\textbf{USD 505.72}$ (correct upto 2 places after decimal point) which was way below what my best model predicted it to be!  \n",
    " \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ssahoo_3_UC_002.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
